{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for loading FEAT model from original paper and get new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from _load_llm_results import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import importlib\n",
    "import sys; sys.path.append('../')\n",
    "from evaluate_model import read_data\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "data_dir = '../data'\n",
    "paper_dir = '../paper/floats/'\n",
    "\n",
    "\"\"\"Model features\n",
    "(reversed)\n",
    "[(sum_enc_during_htn_meds_3>=1.500000)]\n",
    "[(median_enc_during_htn_meds_4_plus>=1.250000)]\n",
    "[sd_enc_during_htn_meds_2]\n",
    "[(mean_systolic>=128.641357)]\n",
    "[(max.CALCIUM>=10.150000)]\n",
    "[(re_htn_spec_sum>=40.500000)]\n",
    "\"\"\"\n",
    "\n",
    "# Hardcoding the best FEAT model from original paper \n",
    "class FeatTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ss = StandardScaler()\n",
    "        self.feature_names = [\n",
    "            'sum_enc_during_htn_meds_3>1',\n",
    "            'median_enc_during_htn_meds_4_plus>1.25',\n",
    "            'sd_enc_during_htn_meds_2',\n",
    "            'mean_systolic>128.6',\n",
    "            'max.CALCIUM>10.1',\n",
    "            're_htn_spec_sum>40']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.ss.fit(self.feat_model(X))\n",
    "        return self\n",
    "    \n",
    "    def feat_model(self, X):\n",
    "        if type(X).__name__ == 'DataFrame':\n",
    "            X = X.values\n",
    "        Phi = []\n",
    "        Phi.append(X[:,280] >= 1.5)\n",
    "        Phi.append(X[:,285] >= 1.25)\n",
    "        Phi.append(X[:,287])\n",
    "        Phi.append(X[:,19]>=128.641357)\n",
    "        Phi.append(X[:,89]>=10.15)\n",
    "        Phi.append(X[:,308]>=40.5)\n",
    "       \n",
    "        Phi = np.array(Phi).transpose()\n",
    "        return Phi\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Phi = self.ss.transform(self.feat_model(X))\n",
    "        return Phi\n",
    "\n",
    "ft_lr_estimator = Pipeline( [\n",
    "    ('prep', FeatTransformer()),\n",
    "    ('est', LogisticRegression(C=1.0, penalty='l2', intercept_scaling=1.0, solver='liblinear'))\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test dataset (300 random patients)\n",
    "targets = {\n",
    "            'htn_dx_ia':'Htndx',\n",
    "            'res_htn_dx_ia':'ResHtndx', \n",
    "            'htn_hypok_dx_ia':'HtnHypoKdx', \n",
    "            'HTN_heuristic':'HtnHeuri', \n",
    "            'res_HTN_heuristic':'ResHtnHeuri',\n",
    "            'hypoK_heuristic_v4':'HtnHypoKHeuri'\n",
    "            }\n",
    "\n",
    "drop_cols = ['UNI_ID'] + list(targets.keys())\n",
    "\n",
    "df_train = pd.read_csv(\n",
    "            '../data/Dataset' + str(101) + '/' + 'ResHtndx' + '/' + 'ResHtndxATrain.csv')\n",
    "\n",
    "X_train = df_train.drop(drop_cols,axis=1)\n",
    "y_train = df_train['res_htn_dx_ia'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_lr_estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(val, n = 1000, fn=np.mean):\n",
    "    val_samples = []\n",
    "    for i in range(n):\n",
    "        sample = np.random.randint(0,len(val)-1, size=len(val))\n",
    "        val_samples.append( fn(val[sample]) )\n",
    "    m = np.mean(val_samples)\n",
    "    sd = np.std(val_samples)\n",
    "    ci_upper  = np.quantile(val_samples,0.95)\n",
    "    ci_lower  = np.quantile(val_samples,0.05)\n",
    "    return m, sd, ci_upper,ci_lower\n",
    "\n",
    "\n",
    "def evaluate_all_folds(metric, feat_model, target, res_dict, folds=['A', 'B', 'C', 'D', 'E'], bootstrap=False):\n",
    "    for FOLD in folds:\n",
    "        X_train, y_train, X_test, y_test = read_data(\n",
    "            target, FOLD, 1, False,\n",
    "            False, data_dir, 1318\n",
    "        )\n",
    "\n",
    "        def eval(X, y):\n",
    "            if metric in [average_precision_score, roc_auc_score]:\n",
    "                return metric(y, feat_model.predict_proba(X)[:,1])\n",
    "            else:\n",
    "                return feat_model.predict(X)\n",
    "\n",
    "        entry = f\"{metric.__name__}_fold_out_{FOLD}\"\n",
    "        if bootstrap:\n",
    "            val_samples = []\n",
    "            for i in tqdm(range(1_000)):\n",
    "                samples = np.random.randint(0,len(X_test)-1, size=len(X_test))\n",
    "                val_samples.append( eval(X_test.iloc[samples, :], y_test[samples]) )\n",
    "\n",
    "            res_dict[f\"{entry}_mean\"] = np.mean(val_samples)\n",
    "            res_dict[f\"{entry}_std\"] = np.std(val_samples)\n",
    "            res_dict[f\"{entry}_ci_upper\"] = np.quantile(val_samples,0.95)\n",
    "            res_dict[f\"{entry}_ci_lower\"] = np.quantile(val_samples,0.05)\n",
    "        else:\n",
    "            res_dict[entry] = eval(X_test, y_test)\n",
    "\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_performances = {\n",
    "    'size' : 45,\n",
    "    'target' : 'ResHtndx',\n",
    "    'model' : 'FEAT',\n",
    "    'scale' : False,\n",
    "    'RunID' : 1,\n",
    "    'fold' : 'A',\n",
    "    'random_state' : 1318 \n",
    "}\n",
    "\n",
    "for metric_f in [average_precision_score, roc_auc_score]:\n",
    "    held_out_performances = evaluate_all_folds(metric_f, ft_lr_estimator, 'res_htn_dx_ia', held_out_performances, ['A'], bootstrap=True)\n",
    "    \n",
    "\n",
    "held_out_performances = pd.DataFrame().from_records([held_out_performances])\n",
    "print(\"-\"*120)\n",
    "\n",
    "# Create LaTeX table\n",
    "latex_table = held_out_performances.to_latex(\n",
    "    index=True,\n",
    "    column_format=\"lrrr\",\n",
    "    escape=False\n",
    ")\n",
    "\n",
    "# Save LaTeX table to file\n",
    "filename = f\"{paper_dir}/tab_feat.tex\"\n",
    "with open(filename, 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\nLaTeX table saved to {filename}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brush-ehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
